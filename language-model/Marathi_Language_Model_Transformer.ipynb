{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.1.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-marathi/language-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.tokenizer import MarathiTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inltk.tokenizer.MarathiTokenizer"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarathiTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MarathiTokenizer(BaseTokenizer):\n",
    "#     def __init__(self, lang:str):\n",
    "#         self.lang = lang\n",
    "#         self.sp = spm.SentencePieceProcessor()\n",
    "#         self.sp.Load(str(path/\"../tokenizer/marathi_lm.model\"))\n",
    "        \n",
    "#     def tokenizer(self, t:str) -> List[str]:\n",
    "#         return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/marathi_lm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30,000 is the vocab size that we chose in sentencepiece\n",
    "marathi_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=MarathiTokenizer, lang='mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'transformer', tokenizer=tokenizer, vocab=marathi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>िंग ▁जगतात ही ▁मारिया ने ▁नाव ▁कमावले ▁आहे . ▁२००८ ▁व ▁२०१० ▁साली ▁ती ▁सर्वाधिक ▁उत्पन्न ▁मिळवणारी ▁महिला ▁खेळाडू ▁होती . ▁x x bo s ▁{{ माहितीचौकट ▁साहित्यिक | नाव = विष्णू ▁वामन ▁शिरवाडकर | चित्र = ▁x x re p ▁7 ▁ &lt;unk&gt; ▁ &lt;unk&gt; | चित्र _ रुंदी =| चित्र _ शीर्षक =| पूर्ण _ नाव = गजानन ▁रंगनाथ ▁शिरवाडकर | टो पण _ नाव = कुसुमाग्रज |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁कन्ये ने ▁देहत्याग ▁केला . ▁सोलापूर ▁शहरातील ▁विजापूर ▁रस्त्या स ▁लागून ▁कंबर ▁तलाव ▁आहे . या ▁तलाव ाच्या ▁पश्चिमेस ▁ समोरील ▁बाजूस ▁हे ▁मंदिर ▁आहे . ▁सोलापूर ▁जिल्ह्यातील ▁प्रसिद्ध ▁देवस्थान े ▁श्री ▁नागनाथ ▁नागनाथ ▁मंदिर ▁वड वळ ▁मोहोळ ▁सोलापूर ▁सोलापूर ▁पुणे ▁रोडवर ▁श्री ▁भैरवनाथ ▁भैरवनाथ ▁मंदिर ▁तांब ोळे ▁मोहोळ ▁सोलापूर ▁मोहोळ ▁पंढरपूर ▁रोडवर ▁मरी आई ▁देवस्थान ▁चिखल ी ▁मोहोळ ▁सोलापूर ▁मोहोळ ▁पुणे ▁रोडवर ▁श्री ▁विठ्ठल ▁विठ्ठल ▁मंदिर ▁पंढरपूर ▁सोलापूर ▁मोहोळ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁अंतरावर ▁आहे . ▁गावात ▁१ ▁बाह्यरुग्ण ▁वैद्यकीय ▁सुविधा ▁आहे . ▁गावात ▁१ ▁इतर ▁पदवीधर ▁वैद्यक ▁व्यवसायी ▁आहे . ▁गावात ▁शुद्धिकरण ▁केलेल्या ▁नळाच्या ▁पाण्याचा ▁पुरवठा ▁नाही . गावात ▁शुद्धिकरण ▁न ▁केलेल्या ▁नळाच्या ▁पाण्याचा ▁पुरवठा ▁आहे . गावात ▁झाकलेल ्या ▁ विहिरीच्या ▁पाण्याचा ▁पुरवठा ▁नाही . गावात ▁न ▁झाकलेल ्या ▁ विहिरीच्या ▁पाण्याचा ▁पुरवठा ▁आहे . गावात ▁हॅन्डपंपच्या ▁पाण्याचा ▁पुरवठा ▁आहे . गावात ▁ट्यूबवेलच्या ▁/ ▁ बोअरवेलच्या ▁पाण्याचा ▁पुरवठा ▁आहे . गावात</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>चे ▁अखेर चे ▁अधिवेशन ▁भरले . ▁त्यावेळी ▁आठ ▁लाख ाच्या ▁आसपास ▁कार्यकर्ते ▁देशभरात ून ▁एकत्र ▁आले ▁होते . ▁भारताच्या ▁इतिहासातील ▁हा ▁महत्त्वाचा ▁क्षण ▁होता . ▁त्यावेळी ▁अध्यक्ष ीय भा षण ात ▁बॅ . ▁खोब्रागडे ▁म्हणाले , ▁ &lt;unk&gt; अस्पृश्य ांना ▁राजकीय ▁हक्क ▁मिळावे त ▁यासाठी ▁डॉ . ▁आंबेडकरांनी ▁लढा ▁दिला . ▁दि . ▁२९ ▁सप्टेंबर ▁१९५६ ▁ला ▁डॉ . ▁आंबेडकरांच्या ▁अध्यक्ष ेत खाली ▁अखिल ▁भारतीय ▁दलित ▁फेडरेशन च्या ▁ वर्किंग</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁म्हणून ▁आपल्या ▁धर्म पत् ▁नी चा ▁त्याग ▁केला . ▁श्रीराम ▁हा ▁आदर्श ▁शत्रू सुद्धा ▁होता . ▁रावण ाच्या ▁मृत्यूनंतर ▁अग्नि संस्कार ▁करायला ▁त्याचा ▁भाऊ ▁बिभीषण ▁नकार ▁देतो , ▁तेव्हा ▁राम ▁त्याला ▁सांगतो , ▁‘‘ मरण ाबरोबर ▁वैर ▁संपत े . ▁तू ▁जर ▁रावण ाचा ▁अंत्यसंस्कार ▁करणार ▁नसला स , ▁तर ▁मी ▁करीन . ▁तो ▁माझा ही ▁भाऊ च ▁आहे . ’’ ▁श्रीराम ाने ▁धर्माच्या ▁सर्व ▁मर्यादा ▁पाळल्या ▁असे ▁रामायण ातील</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): TransformerXL(\n",
       "    (encoder): Embedding(30000, 410)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=410, out_features=30000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.046154</td>\n",
       "      <td>5.969279</td>\n",
       "      <td>0.214419</td>\n",
       "      <td>19:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.246222</td>\n",
       "      <td>5.162740</td>\n",
       "      <td>0.277931</td>\n",
       "      <td>19:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.646038</td>\n",
       "      <td>4.587741</td>\n",
       "      <td>0.320916</td>\n",
       "      <td>19:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.321971</td>\n",
       "      <td>4.293795</td>\n",
       "      <td>0.342960</td>\n",
       "      <td>19:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.119202</td>\n",
       "      <td>4.163072</td>\n",
       "      <td>0.349948</td>\n",
       "      <td>19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.131173</td>\n",
       "      <td>4.053243</td>\n",
       "      <td>0.358012</td>\n",
       "      <td>19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.941661</td>\n",
       "      <td>3.905173</td>\n",
       "      <td>0.370526</td>\n",
       "      <td>19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.922519</td>\n",
       "      <td>3.796391</td>\n",
       "      <td>0.381385</td>\n",
       "      <td>19:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.752540</td>\n",
       "      <td>3.706470</td>\n",
       "      <td>0.392006</td>\n",
       "      <td>19:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.590728</td>\n",
       "      <td>3.583608</td>\n",
       "      <td>0.406611</td>\n",
       "      <td>19:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.376964</td>\n",
       "      <td>3.459021</td>\n",
       "      <td>0.422325</td>\n",
       "      <td>19:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.345181</td>\n",
       "      <td>3.334092</td>\n",
       "      <td>0.439315</td>\n",
       "      <td>19:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.251031</td>\n",
       "      <td>3.234141</td>\n",
       "      <td>0.454446</td>\n",
       "      <td>19:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.107232</td>\n",
       "      <td>3.129973</td>\n",
       "      <td>0.470105</td>\n",
       "      <td>19:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.894331</td>\n",
       "      <td>3.041914</td>\n",
       "      <td>0.484826</td>\n",
       "      <td>19:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.801406</td>\n",
       "      <td>2.967665</td>\n",
       "      <td>0.497212</td>\n",
       "      <td>19:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.692499</td>\n",
       "      <td>2.911881</td>\n",
       "      <td>0.506430</td>\n",
       "      <td>19:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.682134</td>\n",
       "      <td>2.876472</td>\n",
       "      <td>0.512572</td>\n",
       "      <td>19:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.691091</td>\n",
       "      <td>2.860886</td>\n",
       "      <td>0.515205</td>\n",
       "      <td>19:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.532032</td>\n",
       "      <td>2.857645</td>\n",
       "      <td>0.515809</td>\n",
       "      <td>19:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.21441875398159027.\n",
      "Better model found at epoch 1 with accuracy value: 0.27793118357658386.\n",
      "Better model found at epoch 2 with accuracy value: 0.32091566920280457.\n",
      "Better model found at epoch 3 with accuracy value: 0.3429602384567261.\n",
      "Better model found at epoch 4 with accuracy value: 0.34994783997535706.\n",
      "Better model found at epoch 5 with accuracy value: 0.35801249742507935.\n",
      "Better model found at epoch 6 with accuracy value: 0.37052613496780396.\n",
      "Better model found at epoch 7 with accuracy value: 0.38138526678085327.\n",
      "Better model found at epoch 8 with accuracy value: 0.39200618863105774.\n",
      "Better model found at epoch 9 with accuracy value: 0.4066111445426941.\n",
      "Better model found at epoch 10 with accuracy value: 0.4223254323005676.\n",
      "Better model found at epoch 11 with accuracy value: 0.43931496143341064.\n",
      "Better model found at epoch 12 with accuracy value: 0.45444634556770325.\n",
      "Better model found at epoch 13 with accuracy value: 0.470104843378067.\n",
      "Better model found at epoch 14 with accuracy value: 0.48482587933540344.\n",
      "Better model found at epoch 15 with accuracy value: 0.4972120523452759.\n",
      "Better model found at epoch 16 with accuracy value: 0.5064296126365662.\n",
      "Better model found at epoch 17 with accuracy value: 0.5125716328620911.\n",
      "Better model found at epoch 18 with accuracy value: 0.515204668045044.\n",
      "Better model found at epoch 19 with accuracy value: 0.5158093571662903.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-3, moms=(0.8,0.7), callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"तसेच टायगर कॅपिटल\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "तसेच टायगर कॅपिटल ▁ही ▁अमेरिकेत ▁मेजर ▁लीग ▁बेसबॉल ▁या ▁संघटने तील ▁एक ▁बेसबॉल ▁संघ ▁आहे . ▁हा ▁संघ ▁वॉशिंग्टन ▁ ँ ▁ क्यू अस ▁शहराजवळ ▁स्थित ▁आहे . ▁याचे ▁घर चे ▁सामने ▁विकून ▁विकून ▁येणारी ▁विक्री ▁विक्री ▁युनिव्हर्सिटी तून ही ▁केली ▁जात ▁नाही\n",
      "तसेच टायगर कॅपिटल ▁हा ▁२६ ▁ऑक्टोबर ▁२०१० ▁पासून ▁विश्वासू ▁वंशाचे ▁एक ▁प्रकार ▁आहे . ▁या ▁दुर चित्र धी वर ▁वर्ल्ड ▁व ेन ▁व ▁ग िंग ▁या ▁दोन ▁अ विचार ी ▁सहकार्याने ▁श ॅग मधील ▁सुट्टी चा ▁उच्चांक ▁चालू ▁झाला . ▁ई थ िक\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.9) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.42045342368867"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.857645)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding vectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-marathi/language-model')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(path / 'MarathiDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 410])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 410)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings_transformer.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.010937</td>\n",
       "      <td>0.113969</td>\n",
       "      <td>0.147530</td>\n",
       "      <td>-0.121011</td>\n",
       "      <td>-0.278890</td>\n",
       "      <td>-0.229895</td>\n",
       "      <td>0.030712</td>\n",
       "      <td>-0.257502</td>\n",
       "      <td>0.031346</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134024</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>-0.273533</td>\n",
       "      <td>0.060012</td>\n",
       "      <td>0.151923</td>\n",
       "      <td>-0.245915</td>\n",
       "      <td>0.319201</td>\n",
       "      <td>0.240032</td>\n",
       "      <td>0.149429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.295039</td>\n",
       "      <td>-0.018878</td>\n",
       "      <td>0.072087</td>\n",
       "      <td>0.047736</td>\n",
       "      <td>-0.206541</td>\n",
       "      <td>0.199635</td>\n",
       "      <td>-0.135650</td>\n",
       "      <td>-0.045816</td>\n",
       "      <td>-0.195255</td>\n",
       "      <td>-0.088934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.101281</td>\n",
       "      <td>0.030086</td>\n",
       "      <td>0.114028</td>\n",
       "      <td>0.121945</td>\n",
       "      <td>-0.025101</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>-0.104296</td>\n",
       "      <td>0.199662</td>\n",
       "      <td>0.024636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300438</td>\n",
       "      <td>-0.021809</td>\n",
       "      <td>0.069141</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>-0.206079</td>\n",
       "      <td>0.194410</td>\n",
       "      <td>-0.131522</td>\n",
       "      <td>-0.045516</td>\n",
       "      <td>-0.199033</td>\n",
       "      <td>-0.078396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.102489</td>\n",
       "      <td>0.030537</td>\n",
       "      <td>0.116891</td>\n",
       "      <td>0.122554</td>\n",
       "      <td>-0.025217</td>\n",
       "      <td>0.065190</td>\n",
       "      <td>-0.098409</td>\n",
       "      <td>0.209584</td>\n",
       "      <td>0.019984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.309477</td>\n",
       "      <td>0.084436</td>\n",
       "      <td>0.105854</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>-0.212537</td>\n",
       "      <td>-0.559150</td>\n",
       "      <td>-0.508897</td>\n",
       "      <td>0.101343</td>\n",
       "      <td>0.247154</td>\n",
       "      <td>0.137923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141037</td>\n",
       "      <td>-0.247002</td>\n",
       "      <td>0.350776</td>\n",
       "      <td>0.132599</td>\n",
       "      <td>0.144243</td>\n",
       "      <td>-0.103490</td>\n",
       "      <td>-0.531618</td>\n",
       "      <td>-1.074541</td>\n",
       "      <td>0.289434</td>\n",
       "      <td>0.028357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.205207</td>\n",
       "      <td>0.317478</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>-0.071201</td>\n",
       "      <td>-0.112540</td>\n",
       "      <td>-0.089981</td>\n",
       "      <td>-0.029354</td>\n",
       "      <td>0.013353</td>\n",
       "      <td>-0.082606</td>\n",
       "      <td>-0.297414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095006</td>\n",
       "      <td>-0.032324</td>\n",
       "      <td>0.174386</td>\n",
       "      <td>-0.102697</td>\n",
       "      <td>0.104492</td>\n",
       "      <td>0.034446</td>\n",
       "      <td>-0.277193</td>\n",
       "      <td>-0.300818</td>\n",
       "      <td>-0.232282</td>\n",
       "      <td>0.034038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.010937  0.113969  0.147530 -0.121011 -0.278890 -0.229895  0.030712   \n",
       "1  0.295039 -0.018878  0.072087  0.047736 -0.206541  0.199635 -0.135650   \n",
       "2  0.300438 -0.021809  0.069141  0.050555 -0.206079  0.194410 -0.131522   \n",
       "3  0.309477  0.084436  0.105854  0.014735 -0.212537 -0.559150 -0.508897   \n",
       "4 -0.205207  0.317478  0.022261 -0.071201 -0.112540 -0.089981 -0.029354   \n",
       "\n",
       "        7         8         9    ...       400       401       402       403  \\\n",
       "0 -0.257502  0.031346  0.064200  ... -0.134024  0.036281  0.020691 -0.273533   \n",
       "1 -0.045816 -0.195255 -0.088934  ...  0.003693  0.101281  0.030086  0.114028   \n",
       "2 -0.045516 -0.199033 -0.078396  ...  0.006615  0.102489  0.030537  0.116891   \n",
       "3  0.101343  0.247154  0.137923  ...  0.141037 -0.247002  0.350776  0.132599   \n",
       "4  0.013353 -0.082606 -0.297414  ... -0.095006 -0.032324  0.174386 -0.102697   \n",
       "\n",
       "        404       405       406       407       408       409  \n",
       "0  0.060012  0.151923 -0.245915  0.319201  0.240032  0.149429  \n",
       "1  0.121945 -0.025101  0.056296 -0.104296  0.199662  0.024636  \n",
       "2  0.122554 -0.025217  0.065190 -0.098409  0.209584  0.019984  \n",
       "3  0.144243 -0.103490 -0.531618 -1.074541  0.289434  0.028357  \n",
       "4  0.104492  0.034446 -0.277193 -0.300818 -0.232282  0.034038  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3      .\n",
       "4      ▁"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('embeddings_transformer_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2950, -0.0189,  0.0721,  0.0477, -0.2065,  0.1996, -0.1357, -0.0458,\n",
       "        -0.1953, -0.0889,  0.0342,  0.0526,  0.0017, -0.2536,  0.1059, -0.1432,\n",
       "        -0.2187,  0.0756, -0.0183,  0.0765,  0.0174,  0.0833, -0.0759,  0.2628,\n",
       "        -0.1734, -0.0598, -0.1775,  0.0486,  0.1361, -0.2029, -0.1878, -0.1599,\n",
       "        -0.1213,  0.0983, -0.0728,  0.1632,  0.0142,  0.0435,  0.0396, -0.1823,\n",
       "        -0.0212,  0.0931,  0.2087, -0.0341, -0.3015,  0.2613,  0.0362, -0.1587,\n",
       "         0.0619,  0.0293,  0.1595,  0.2002,  0.1558,  0.0987, -0.1003,  0.1076,\n",
       "        -0.1100,  0.0070,  0.0303, -0.2286, -0.2683,  0.0429, -0.1596,  0.3389,\n",
       "         0.1505, -0.1421, -0.0898,  0.0534, -0.0639, -0.4874,  0.2601, -0.1792,\n",
       "        -0.1144, -0.1197,  0.1806,  0.0877,  0.2033,  0.1452,  0.0564,  0.3800,\n",
       "        -0.1298, -0.1060, -0.1858,  0.0663,  0.0331,  0.2009, -0.0947,  0.0275,\n",
       "        -0.0091,  0.0473, -0.0577, -0.2623,  0.0455, -0.1023,  0.0337,  0.0830,\n",
       "        -0.1576, -0.0552,  0.1055, -0.0453,  0.1472,  0.1947, -0.1932,  0.1416,\n",
       "         0.2219, -0.0765,  0.1756,  0.0570,  0.1119,  0.2020,  0.1107, -0.0624,\n",
       "        -0.1053, -0.0380,  0.1294,  0.1296, -0.1464,  0.2594, -0.1986, -0.1348,\n",
       "        -0.1170, -0.1502,  0.1049, -0.0332,  0.1237,  0.4600,  0.1405, -0.2790,\n",
       "        -0.1664, -0.1507,  0.1250,  0.2437, -0.1357, -0.2354,  0.0618, -0.0280,\n",
       "         0.0337,  0.0507,  0.0681, -0.0813,  0.1823,  0.0692, -0.0718,  0.0133,\n",
       "        -0.0236,  0.1473, -0.1090, -0.0321, -0.0332,  0.1253, -0.3146, -0.0488,\n",
       "         0.0357, -0.0458, -0.0246,  0.0725, -0.0665,  0.1751, -0.2468, -0.0091,\n",
       "         0.0133, -0.0308,  0.0057,  0.1410,  0.1566,  0.1456,  0.0880,  0.0110,\n",
       "         0.1098,  0.0159,  0.1911,  0.1807,  0.1233, -0.0041,  0.1223,  0.2050,\n",
       "        -0.0051, -0.1680,  0.0971,  0.0740,  0.0831,  0.0073,  0.0317,  0.0390,\n",
       "         0.0439, -0.2318,  0.0808, -0.1134, -0.0065, -0.2096,  0.1244, -0.2723,\n",
       "         0.1324,  0.0208, -0.0019, -0.1176,  0.1313,  0.1126,  0.0301,  0.1170,\n",
       "         0.0298,  0.1159,  0.0740,  0.0478, -0.3161,  0.0736,  0.1303,  0.2721,\n",
       "        -0.2719, -0.0549,  0.0188, -0.1210, -0.1024,  0.0433,  0.1516, -0.0132,\n",
       "        -0.1896, -0.0322,  0.0699, -0.1009,  0.1460,  0.2084, -0.0600,  0.1513,\n",
       "        -0.0416, -0.0338, -0.1067, -0.1465,  0.0635,  0.2286,  0.2506,  0.1481,\n",
       "        -0.0740, -0.1322, -0.1210,  0.3079, -0.0709, -0.0090,  0.0753,  0.1038,\n",
       "         0.4381, -0.0453,  0.2700, -0.1578,  0.0611,  0.0041,  0.0647, -0.1909,\n",
       "         0.0381, -0.4611, -0.1986,  0.0271,  0.2308, -0.2556,  0.1069,  0.1481,\n",
       "         0.0097,  0.1016, -0.0828, -0.0724,  0.0553, -0.0324, -0.0197,  0.2902,\n",
       "        -0.0353,  0.0069, -0.0044,  0.0307, -0.0696, -0.3078,  0.0932, -0.0066,\n",
       "        -0.0824, -0.1095,  0.0818,  0.1038, -0.0317, -0.0043,  0.1249,  0.0462,\n",
       "        -0.0361,  0.0510,  0.0950, -0.1197,  0.1784,  0.2363, -0.0646,  0.1816,\n",
       "         0.1614, -0.0356,  0.0641,  0.0066,  0.3930,  0.0738,  0.0147,  0.0476,\n",
       "        -0.0607,  0.0051, -0.0507, -0.0648, -0.0728,  0.2617, -0.2326,  0.1689,\n",
       "         0.2299,  0.1389,  0.1126,  0.0116,  0.0645, -0.0608, -0.2252,  0.0928,\n",
       "         0.1027,  0.3943,  0.0384, -0.0920,  0.3108, -0.0914,  0.1360,  0.0175,\n",
       "         0.3760,  0.2048, -0.0445, -0.3131,  0.0485,  0.0949, -0.1361, -0.0611,\n",
       "         0.0024,  0.1845,  0.0201, -0.1664, -0.1156,  0.3418,  0.1131,  0.0821,\n",
       "         0.1391, -0.0719, -0.0931,  0.2262, -0.0661, -0.0373, -0.0899,  0.0722,\n",
       "         0.2239,  0.0483,  0.2297, -0.1701,  0.0069,  0.0567,  0.0742,  0.0039,\n",
       "        -0.2042,  0.0614,  0.1258, -0.0705,  0.0521,  0.0160,  0.3129, -0.0469,\n",
       "        -0.0528,  0.1462,  0.0272, -0.0024, -0.1117,  0.1272, -0.1439,  0.0230,\n",
       "         0.0855,  0.0972, -0.1689, -0.2738,  0.1728, -0.1168, -0.0473, -0.0598,\n",
       "         0.0815,  0.1708, -0.0473,  0.0596, -0.1715,  0.0157,  0.1400,  0.0282,\n",
       "         0.1759,  0.0696,  0.0708,  0.1900,  0.1730,  0.0083,  0.1599,  0.0861,\n",
       "         0.0715,  0.1762, -0.0185,  0.0482,  0.0355, -0.0338,  0.0164,  0.0744,\n",
       "         0.0037,  0.1013,  0.0301,  0.1140,  0.1219, -0.0251,  0.0563, -0.1043,\n",
       "         0.1997,  0.0246], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
